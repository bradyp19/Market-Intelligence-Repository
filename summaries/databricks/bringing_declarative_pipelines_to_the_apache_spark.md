Bringing Declarative Pipelines to the Apache Spark™ Open Source Project (, 2025-06-12)
Source: https://www.databricks.com/blog/bringing-declarative-pipelines-apache-spark-open-source-project
Summary: Apache Spark™ has become the de facto engine for big data processing, powering workloads at some of the largest organizations in the world. Over the past decade, we’ve seen Apache Spark evolve from a powerful general-purpose compute engine into a critical layer of the Open Lakehouse Architecture - with Spark SQL, Structured Streaming, open table formats, and unified governance serving as pillars for modern data platforms.

 With the recent release of Apache Spark 4.0, that evolution continues with major advances in streaming, Python, SQL, and semi-structured data.
Key Features:
• Spark Declarative Pipelines in action Built with openness and composability in mind, Spark Declarative Pipelines offers: Declarative APIs for defining tables and transformations Native support for both batch and streaming data flows Data-aware orchestration with automatic dependency tracking, execution ordering, and backfill handling Automatic checkpointing, retries, and incremental processing for streaming data Support for both SQL and Python Execution transparency with full access to underlying Spark plans And most importantly, it’s Apache Spark all the way down - no wrappers or black boxes.
Executive Insight: This announcement highlights new capabilities or strategic direction relevant to customers or the business.
